# ----------------------------------------------------------------------
# Code generated by AI agent: data_cleaning_agent
# ----------------------------------------------------------------------


def data_cleaner(data_raw):
    import pandas as pd
    import numpy as np
    import warnings
    # Suppress pandas warnings for clean output
    warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)
    pd.set_option('mode.chained_assignment', None)
    
    # ALWAYS work on a copy to preserve original
    data = data_raw.copy()
    
    # Initialize tracking variables
    original_shape = data.shape
    original_rows = len(data)
    cleaning_log = []
    
    print(f"üßπ Starting data cleaning: {original_shape[0]} rows √ó {original_shape[1]} columns")
    
    try:
        # STEP 1: Data Type Optimization
        print("üìä Step 1: Optimizing data types...")
        data['price'] = pd.to_numeric(data['price'], errors='coerce')
        data['quantity'] = pd.to_numeric(data['quantity'], errors='coerce')
        data['rating'] = pd.to_numeric(data['rating'], errors='coerce')
        data['id'] = data['id'].astype(np.int32)  # Example optimization
        data['in_stock'] = data['in_stock'].astype(bool)
        data['category'] = data['category'].astype('category')

        # STEP 2: Handle Missing Values (PRIORITIZE IMPUTATION)
        print("üîß Step 2: Handling missing values...")
        for column in ['price', 'quantity', 'rating']:
            median_val = data[column].median()
            data[column].fillna(median_val, inplace=True)  # Impute with median for numeric
            
        # While no categorical missing values, we include example lines for completeness
        # data['category'].fillna('Unknown', inplace=True)

        # STEP 3: Remove Duplicates
        print("üóëÔ∏è Step 3: Removing duplicates...")
        duplicates_before = data.duplicated().sum()
        if duplicates_before > 0:
            data = data.drop_duplicates()
            cleaning_log.append(f"Removed {duplicates_before} duplicate rows")
        
        # STEP 4: Handle Outliers (CONSERVATIVE)
        print("üìà Step 4: Conservative outlier handling...")
        # Handle outliers using the IQR method if applicable
        for column in ['price', 'quantity', 'rating']:
            Q1 = data[column].quantile(0.25)
            Q3 = data[column].quantile(0.75)
            IQR = Q3 - Q1
            # Remove rows with outliers conservatively (only if requested)
            data = data[(data[column] >= (Q1 - 3 * IQR)) & (data[column] <= (Q3 + 3 * IQR))]
        
        # STEP 5: Final Validation and Cleanup
        print("‚úÖ Step 5: Final validation...")
        empty_rows = data.isnull().all(axis=1).sum()
        if empty_rows > 0:
            data = data.dropna(how='all')
            cleaning_log.append(f"Removed {empty_rows} completely empty rows")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error during cleaning: {str(e)}")
        print("üîÑ Returning original data to prevent data loss")
        return data_raw.copy()
    
    # MANDATORY: Data preservation validation
    final_shape = data.shape
    final_rows = len(data)
    data_loss_pct = ((original_rows - final_rows) / original_rows) * 100 if original_rows > 0 else 0
    
    # Comprehensive reporting
    print(f"\nüìà CLEANING SUMMARY:")
    print(f"   Original: {original_shape[0]} rows √ó {original_shape[1]} columns")
    print(f"   Final: {final_shape[0]} rows √ó {final_shape[1]} columns")
    print(f"   Data retention: {100-data_loss_pct:.1f}%")
    
    if cleaning_log:
        print(f"\nüìù Actions taken:")
        for action in cleaning_log:
            print(f"   ‚Ä¢ {action}")
    
    # Critical validation checks
    if data_loss_pct > 25:
        print(f"üö® CRITICAL WARNING: High data loss ({data_loss_pct:.1f}%)!")
        print(f"   Consider using more conservative cleaning approaches")
    
    if final_rows == 0:
        print(f"‚ùå FATAL ERROR: All data was removed! Returning original data")
        return data_raw.copy()
    
    if final_rows < 10 and original_rows > 100:
        print(f"‚ö†Ô∏è WARNING: Extreme data reduction ({final_rows} remaining from {original_rows})")
    
    # Reset pandas options
    pd.set_option('mode.chained_assignment', 'warn')
    warnings.resetwarnings()
    
    print(f"‚úÖ Data cleaning completed successfully!")
    return data